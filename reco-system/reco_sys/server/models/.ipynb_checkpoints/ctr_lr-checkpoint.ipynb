{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# 如果当前代码文件运行测试需要加入修改路径，避免出现后导包问题\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "\n",
    "PYSPARK_PYTHON = \"/miniconda2/envs/reco_sys/bin/python\"\n",
    "# 当存在多个版本时，不指定很可能会导致出错\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYSPARK_PYTHON\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from offline import SparkSessionBase\n",
    "\n",
    "class CtrLogisticRegression(SparkSessionBase):\n",
    "\n",
    "    SPARK_APP_NAME = \"ctrLogisticRegression\"\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.spark = self._create_spark_hbase()\n",
    "\n",
    "ctr = CtrLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、读取用户点击行为表，与用户画像和文章画像，构造训练样本\n",
    "ctr.spark.sql('use profile')\n",
    "news_article_basic = ctr.spark.sql(\"select user_id, article_id, channel_id, clicked from user_article_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+-------+\n",
      "|            user_id|         article_id|channel_id|clicked|\n",
      "+-------------------+-------------------+----------+-------+\n",
      "|1105045287866466304|              14225|         0|  false|\n",
      "|1106476833370537984|              14208|         0|  false|\n",
      "|1109980466942836736|              19233|         0|  false|\n",
      "|1109980466942836736|              44737|         0|  false|\n",
      "|1109993249109442560|              17283|         0|  false|\n",
      "|1111189494544990208|              19322|         0|  false|\n",
      "|1111524501104885760|              44161|         0|  false|\n",
      "|1112727762809913344|              18172|        18|   true|\n",
      "|1113020831425888256|1112592065390182400|         0|  false|\n",
      "|1114863735962337280|              17665|         0|  false|\n",
      "|1114863741448486912|              14208|         0|  false|\n",
      "|1114863751909081088|              13751|         0|  false|\n",
      "|1114863846486441984|              17940|         0|  false|\n",
      "|1114863941936218112|              15196|         0|  false|\n",
      "|1114863998437687296|              19233|         0|  false|\n",
      "|1114864164158832640|             141431|         0|  false|\n",
      "|1114864237131333632|              13797|         0|  false|\n",
      "|1114864354622177280|             134812|         0|  false|\n",
      "|1115089292662669312|1112608068731928576|         0|  false|\n",
      "|1115534909935452160|              18156|         0|  false|\n",
      "+-------------------+-------------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_article_basic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取用户画像的数据\n",
    "user_profile_hbase = ctr.spark.sql(\n",
    "    \"select user_id, information.birthday, information.gender, article_partial, env from user_profile_hbase\")\n",
    "user_profile_hbase = user_profile_hbase.drop('env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+--------------------+\n",
      "|             user_id|birthday|gender|     article_partial|\n",
      "+--------------------+--------+------+--------------------+\n",
      "|              user:1|     0.0|  null|Map(18:vars -> 0....|\n",
      "|             user:10|     0.0|  null|Map(18:tp2 -> 0.2...|\n",
      "|             user:11|     0.0|  null|               Map()|\n",
      "|user:110249052282...|     0.0|  null|               Map()|\n",
      "|user:110319567345...|    null|  null|Map(18:Animal -> ...|\n",
      "|user:110504528786...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110509388310...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110510518565...|    null|  null|Map(18:SHOldboySt...|\n",
      "|user:110639618314...|    null|  null|Map(18:tp2 -> 0.2...|\n",
      "|user:110647320376...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110647683337...|    null|  null|Map(18:text -> 1....|\n",
      "|user:110826490119...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110997636345...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110997980510...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110998046694...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110998427383...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110999324910...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110999459420...|    null|  null|Map(18:tp2 -> 0.2...|\n",
      "|user:110999526437...|    null|  null|Map(18:text -> 0....|\n",
      "|user:110999568377...|    null|  null|Map(18:text -> 0....|\n",
      "+--------------------+--------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_profile_hbase.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对用户ID做处理\n",
    "def get_user_id(row):\n",
    "    return int(row.user_id.split(':')[1]), row.birthday, row.gender, row.article_partial\n",
    "\n",
    "user_profile_hbase = user_profile_hbase.rdd.map(get_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于其中toDF存在一些列没办法确定类型，手动指定DataFrame列的类型\n",
    "_schema = StructType([\n",
    "    StructField('user_id', LongType()),\n",
    "    StructField('birthday', DoubleType()),\n",
    "    StructField('gender', BooleanType()),\n",
    "    StructField('article_partial', MapType(StringType(), DoubleType()))\n",
    "])\n",
    "\n",
    "user_profile_hbase = ctr.spark.createDataFrame(user_profile_hbase, schema=_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+\n",
      "|            user_id|birthday|gender|     article_partial|\n",
      "+-------------------+--------+------+--------------------+\n",
      "|                  1|     0.0|  null|Map(18:vars -> 0....|\n",
      "|                 10|     0.0|  null|Map(18:tp2 -> 0.2...|\n",
      "|                 11|     0.0|  null|               Map()|\n",
      "|1102490522829717504|     0.0|  null|               Map()|\n",
      "|1103195673450250240|    null|  null|Map(18:Animal -> ...|\n",
      "|1105045287866466304|    null|  null|Map(18:text -> 0....|\n",
      "|1105093883106164736|    null|  null|Map(18:text -> 0....|\n",
      "|1105105185656537088|    null|  null|Map(18:SHOldboySt...|\n",
      "|1106396183141548032|    null|  null|Map(18:tp2 -> 0.2...|\n",
      "|1106473203766657024|    null|  null|Map(18:text -> 0....|\n",
      "|1106476833370537984|    null|  null|Map(18:text -> 1....|\n",
      "|1108264901190615040|    null|  null|Map(18:text -> 0....|\n",
      "|1109976363453906944|    null|  null|Map(18:text -> 0....|\n",
      "|1109979805106831360|    null|  null|Map(18:text -> 0....|\n",
      "|1109980466942836736|    null|  null|Map(18:text -> 0....|\n",
      "|1109984273839947776|    null|  null|Map(18:text -> 0....|\n",
      "|1109993249109442560|    null|  null|Map(18:text -> 0....|\n",
      "|1109994594201763840|    null|  null|Map(18:tp2 -> 0.2...|\n",
      "|1109995264376045568|    null|  null|Map(18:text -> 0....|\n",
      "|1109995683777085440|    null|  null|Map(18:text -> 0....|\n",
      "+-------------------+--------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_profile_hbase.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并用户点击行为表与用户画像表，并进行相应的删除无用特征\n",
    "train = news_article_basic.join(user_profile_hbase, on=['user_id'], how='left').drop('birthday').drop('channel_id').drop('gender')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------+--------------------+\n",
      "|            user_id|article_id|clicked|     article_partial|\n",
      "+-------------------+----------+-------+--------------------+\n",
      "|1106473203766657024|     16005|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     14335|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     13778|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     13039|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     13648|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     17304|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     19233|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     44466|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     18795|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|    134812|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     13357|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     19171|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     44104|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     13340|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     14225|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     44739|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     19016|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|    136500|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     13797|  false|Map(18:text -> 0....|\n",
      "|1106473203766657024|     14973|  false|Map(18:text -> 0....|\n",
      "+-------------------+----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并文章的向量以及文章的权重特征，文章所属的真正频道ID\n",
    "ctr.spark.sql('use article')\n",
    "article_vector = ctr.spark.sql(\"select * from article_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article = train.join(article_vector, on=['article_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文章画像\n",
    "article_profile = ctr.spark.sql(\"select article_id, keywords from article_profile\")\n",
    "\n",
    "def get_article_weights(row):\n",
    "    \n",
    "    try:\n",
    "        weights = sorted(row.keywords.values())[:10]\n",
    "    except Exception as e:\n",
    "        weights = [0.0] * 10\n",
    "    \n",
    "    return row.article_id, weights\n",
    "\n",
    "article_profile = article_profile.rdd.map(get_article_weights).toDF(['article_id', 'article_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并文章权重与样本\n",
    "train_user_article = train_user_article.join(article_profile, on=['article_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保留了用户的每个频道的关键词权重，找到用户对应操作文章的所属频道的关键词权重\n",
    "train_user_article = train_user_article.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['article_id', 'user_id', 'channel_id', 'articlevector', 'user_weights', 'article_weights', 'clicked']\n",
    "def get_user_weights(row):\n",
    "\n",
    "    from pyspark.ml.linalg import Vectors\n",
    "    try:\n",
    "        user_weights = sorted([row.article_partial[key] for key in row.article_partial.keys() if key.split(':')[0] == str(row.channel_id)])[\n",
    "                  :10]\n",
    "    except Exception:\n",
    "        user_weights = [0.0] * 10\n",
    "\n",
    "    return row.article_id, row.user_id, row.channel_id, Vectors.dense(row.articlevector), Vectors.dense(\n",
    "        user_weights), Vectors.dense(row.article_weights), int(row.clicked)\n",
    "\n",
    "train_vector = train_user_article.rdd.map(get_user_weights).toDF(columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集所有特征到一个features列\n",
    "train_res = VectorAssembler().setInputCols(columns[2:6]).setOutputCol('features').transform(train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[article_id: bigint, user_id: bigint, channel_id: bigint, articlevector: vector, user_weights: vector, article_weights: vector, clicked: bigint, features: vector]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
