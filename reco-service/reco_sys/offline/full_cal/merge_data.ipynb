{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/toutiao_project/reco_sys\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# 如果当前代码文件运行测试需要加入修改路径，避免出现后导包问题\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "print(BASE_DIR)\n",
    "PYSPARK_PYTHON = \"/miniconda2/envs/reco_sys/bin/python\"\n",
    "# 当存在多个版本时，不指定很可能会导致出错\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYSPARK_PYTHON\n",
    "from offline import SparkSessionBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 初始化spark信息\n",
    "class OriginArticleData(SparkSessionBase):\n",
    "    SPARK_APP_NAME = 'originaldata'\n",
    "    SPARK_URL = 'yarn'\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.spark = self._create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = OriginArticleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oa.spark.sql(\"use toutiao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取new_basic, news_content两张表合并，取出article_id, channel_id, title, content\n",
    "basic_content = oa.spark.sql(\"select a.article_id, a.channel_id, a.title, b.content from news_article_basic a inner join news_article_content b on a.article_id=b.article_id where a.article_id=116636\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+--------------------+\n",
      "|article_id|channel_id|          title|             content|\n",
      "+----------+----------+---------------+--------------------+\n",
      "|    116636|        18|动态再平衡投资策略历史数据回测|<p>赚钱是个俗气的话题，但又是人...|\n",
      "+----------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "basic_content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章内容去按照channel_id取出channel_name合并\n",
    "basic_content.registerTempTable(\"temptable\")\n",
    "channel_basic_content = oa.spark.sql(\"select t.*, n.channel_name from temptable t left join news_channel n on t.channel_id=n.channel_id\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+--------------------+------------+\n",
      "|article_id|channel_id|          title|             content|channel_name|\n",
      "+----------+----------+---------------+--------------------+------------+\n",
      "|    116636|        18|动态再平衡投资策略历史数据回测|<p>赚钱是个俗气的话题，但又是人...|      python|\n",
      "+----------+----------+---------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_basic_content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并文章的一些词语到一个完整内容\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "oa.spark.sql(\"use article\")\n",
    "sentence_df = channel_basic_content.select(\"article_id\", \"channel_id\", \"channel_name\", \"title\", \"content\", \n",
    "                             F.concat_ws(\",\", \n",
    "                                        channel_basic_content.channel_name,\n",
    "                                        channel_basic_content.title,\n",
    "                                        channel_basic_content.content).alias('sentence'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------------+--------------------+--------------------+\n",
      "|article_id|channel_id|channel_name|          title|             content|            sentence|\n",
      "+----------+----------+------------+---------------+--------------------+--------------------+\n",
      "|    116636|        18|      python|动态再平衡投资策略历史数据回测|<p>赚钱是个俗气的话题，但又是人...|python,动态再平衡投资策略历...|\n",
      "+----------+----------+------------+---------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del basic_content\n",
    "del channel_basic_content\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算TFIDF\n",
    "oa.spark.sql(\"use article\")\n",
    "\n",
    "article_data = oa.spark.sql(\"select * from article_data where channel_id=18 limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+--------------------+--------------------+--------------------+\n",
      "|article_id|channel_id|channel_name|               title|             content|            sentence|\n",
      "+----------+----------+------------+--------------------+--------------------+--------------------+\n",
      "|     12237|        18|      python|想学习区块链？那就用 Python...|<div id=\"article_...|python,想学习区块链？那就用...|\n",
      "|     12238|        18|      python|鲜为人知的 Python 语法 使...|<p>所有人（好吧，不是所有人）都...|python,鲜为人知的 Pyth...|\n",
      "|     12243|        18|      python|手把手教你写网络爬虫（4）：Scr...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12245|        18|      python|手把手教你写网络爬虫（5）：Pha...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12247|        18|      python|用 Plumbum 开发 Pyth...|<div id=\"article_...|python,用 Plumbum ...|\n",
      "|     12249|        18|      python|手把手教你写网络爬虫（6）：分布式...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12251|        18|      python|手把手教你写网络爬虫（7）：URL...|<p><a href=\"http:...|python,手把手教你写网络爬虫...|\n",
      "|     12252|        18|      python|手把手教你写网络爬虫（8）：彻底解...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12253|        18|      python|      爬取豆瓣短评之《后来的我们》|<p>《后来的我们》上映了，或许大...|python,爬取豆瓣短评之《后来...|\n",
      "|     12254|        18|      python|5 个用 Python 编写 we...|<p><a href=\"http:...|python,5 个用 Pytho...|\n",
      "+----------+----------+------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "def segmentation(partition):\n",
    "    import os\n",
    "    import re\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/root/words\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path).readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    # 分词\n",
    "    def cut_sentence(sentence):\n",
    "        \"\"\"对切割之后的词语进行过滤，去除停用词，保留名词，英文和自定义词库中的词，长度大于2的词\"\"\"\n",
    "        # print(sentence,\"*\"*100)\n",
    "        # eg:[pair('今天', 't'), pair('有', 'd'), pair('雾', 'n'), pair('霾', 'g')]\n",
    "        seg_list = pseg.lcut(sentence)\n",
    "        seg_list = [i for i in seg_list if i.flag not in stopwords_list]\n",
    "        filtered_words_list = []\n",
    "        for seg in seg_list:\n",
    "            # print(seg)\n",
    "            if len(seg.word) <= 1:\n",
    "                continue\n",
    "            elif seg.flag == \"eng\":\n",
    "                if len(seg.word) <= 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    filtered_words_list.append(seg.word)\n",
    "            elif seg.flag.startswith(\"n\"):\n",
    "                filtered_words_list.append(seg.word)\n",
    "            elif seg.flag in [\"x\", \"eng\"]:  # 是自定一个词语或者是英文单词\n",
    "                filtered_words_list.append(seg.word)\n",
    "        return filtered_words_list\n",
    "\n",
    "    for row in partition:\n",
    "        sentence = re.sub(\"<.*?>\", \"\", row.sentence)    # 替换掉标签数据\n",
    "        words = cut_sentence(sentence)\n",
    "        yield row.article_id, row.channel_id, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = article_data.rdd.mapPartitions(segmentation).toDF(['article_id', 'channel_id', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|               words|\n",
      "+----------+----------+--------------------+\n",
      "|     12237|        18|[python, 区块链, Pyt...|\n",
      "|     12238|        18|[python, Python, ...|\n",
      "|     12243|        18|[python, 手把手, 网络,...|\n",
      "|     12245|        18|[python, 手把手, 网络,...|\n",
      "|     12247|        18|[python, Plumbum,...|\n",
      "|     12249|        18|[python, 手把手, 网络,...|\n",
      "|     12251|        18|[python, 手把手, 网络,...|\n",
      "|     12252|        18|[python, 手把手, 网络,...|\n",
      "|     12253|        18|[python, 豆瓣, 大家, ...|\n",
      "|     12254|        18|[python, Python, ...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol='words', outputCol='countFeatures', vocabSize=200*10000, minDF=1.0)\n",
    "cv_model = cv.fit(words_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/CV.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型处理得到结果\n",
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "cv_model = CountVectorizerModel.load(\"hdfs://hadoop-master:9000/headlines/models/CV.model\")\n",
    "cv_result = cv_model.transform(words_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|               words|       countFeatures|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|         1|        17|[Vue, props, 用法, ...|(986,[1,2,3,4,10,...|\n",
      "|         2|        17|[vue, 响应式, 原理, mo...|(986,[2,4,5,10,11...|\n",
      "|         3|        17|[JavaScript, 浅拷贝,...|(986,[0,4,5,11,14...|\n",
      "|         4|        17|[vue2, vuex, elem...|(986,[4,11,16,18,...|\n",
      "|         5|        17|[immutability, Re...|(986,[4,5,10,11,1...|\n",
      "|         6|        17|[node, npm, cnpm,...|(986,[0,2,4,10,11...|\n",
      "|         7|        17|[Web, 工程师, 以太坊, 入...|(986,[2,4,6,8,10,...|\n",
      "|         8|        17|[Web, pa, api, we...|(986,[2,4,11,13,1...|\n",
      "|         9|        17|[vue, 中用, 数据驱动, 视...|(986,[2,4,5,12,14...|\n",
      "|        10|        17|[程序, WebSocket, 长...|(986,[2,4,6,12,18...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(inputCol=\"countFeatures\", outputCol=\"idfFeatures\")\n",
    "idfModel = idf.fit(cv_result)\n",
    "idfModel.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/IDF.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&#',\n",
       " 'String',\n",
       " '代码',\n",
       " '作用域',\n",
       " 'pa',\n",
       " 'key',\n",
       " '客户端',\n",
       " 'jedis',\n",
       " 'public',\n",
       " 'Hooks',\n",
       " '函数',\n",
       " 'ul',\n",
       " '组件',\n",
       " 'scope',\n",
       " 'return',\n",
       " '模块',\n",
       " '方法',\n",
       " 'import',\n",
       " '时候',\n",
       " 'count',\n",
       " 'res',\n",
       " '.h',\n",
       " 'this',\n",
       " 'java',\n",
       " '问题',\n",
       " 'Long',\n",
       " 'Override',\n",
       " 'class',\n",
       " 'com',\n",
       " '声明',\n",
       " 'web',\n",
       " 'name',\n",
       " '线程',\n",
       " 'constructor',\n",
       " 'value',\n",
       " '逻辑',\n",
       " 'props',\n",
       " 'useEffect',\n",
       " 'node',\n",
       " 'start',\n",
       " '插件',\n",
       " '项目',\n",
       " 'field',\n",
       " 'rams',\n",
       " 'vue',\n",
       " 'useState',\n",
       " 'arg',\n",
       " 'Jedis',\n",
       " 'event',\n",
       " 'command',\n",
       " 'jedisPool',\n",
       " '服务端',\n",
       " 'action',\n",
       " '例子',\n",
       " '官方',\n",
       " 'Enumeration',\n",
       " '参数',\n",
       " 'state',\n",
       " 'util',\n",
       " 'close',\n",
       " 'function',\n",
       " '情况',\n",
       " 'catch',\n",
       " 'title',\n",
       " 'const',\n",
       " '文件',\n",
       " 'new',\n",
       " 'set',\n",
       " 'jedisCluster',\n",
       " 'void',\n",
       " 'redis',\n",
       " 'getResource',\n",
       " 'clients',\n",
       " '标识',\n",
       " 'onParseClientResp',\n",
       " 'Thread',\n",
       " 'enu',\n",
       " '.a',\n",
       " 'from',\n",
       " 'hooks',\n",
       " '页面',\n",
       " '全局',\n",
       " 'get',\n",
       " '大家',\n",
       " 'end',\n",
       " 'fireEvent',\n",
       " 'react',\n",
       " 'document',\n",
       " 'times',\n",
       " 'clicked',\n",
       " 'You',\n",
       " 'listener',\n",
       " '赋值',\n",
       " 'Vector',\n",
       " 'server',\n",
       " '结果',\n",
       " 'client',\n",
       " 'var',\n",
       " 'bean',\n",
       " 'isOnline',\n",
       " '降级',\n",
       " 'tml',\n",
       " 'android',\n",
       " 'toast',\n",
       " 'StringTokenizer',\n",
       " 'run',\n",
       " '资源',\n",
       " 'Test',\n",
       " 'bundle',\n",
       " '对象',\n",
       " '业务',\n",
       " '方式',\n",
       " 'lodash',\n",
       " 'true',\n",
       " '数据',\n",
       " 'allPass',\n",
       " 'api',\n",
       " 'jsonObj',\n",
       " 'generated',\n",
       " 'Auto',\n",
       " '方案',\n",
       " 'Vue',\n",
       " 'System',\n",
       " 'setCount',\n",
       " 'tree',\n",
       " '文章',\n",
       " 'main',\n",
       " 'friend',\n",
       " 'println',\n",
       " 'json',\n",
       " 'out',\n",
       " 'Boolean',\n",
       " 'JedisPool',\n",
       " 'TODO',\n",
       " 'while',\n",
       " '团队',\n",
       " 'log',\n",
       " 'for',\n",
       " '消息',\n",
       " 'custom',\n",
       " 'ttl',\n",
       " '状态',\n",
       " 'expire',\n",
       " '定义',\n",
       " 'hello',\n",
       " 'incr',\n",
       " 'false',\n",
       " '手动',\n",
       " '桥接',\n",
       " 'javascript',\n",
       " 'try',\n",
       " 'int',\n",
       " '级别',\n",
       " 'JSBridge',\n",
       " 'seconds',\n",
       " 'shaking',\n",
       " 'status',\n",
       " 'console',\n",
       " 'render',\n",
       " 'static',\n",
       " 'JavaScript',\n",
       " 'getString',\n",
       " 'for循环',\n",
       " '嵌套',\n",
       " 'hdel',\n",
       " 'msg',\n",
       " 'exists',\n",
       " 'args',\n",
       " '文档',\n",
       " '作用域链',\n",
       " '连接池',\n",
       " 'local',\n",
       " '数组',\n",
       " 'ckage',\n",
       " 'stub',\n",
       " 'button',\n",
       " 'API',\n",
       " 'ES6',\n",
       " '社区',\n",
       " 'Thread类',\n",
       " 'export',\n",
       " '热更新',\n",
       " 'curry1',\n",
       " '答案',\n",
       " '地方',\n",
       " 'method',\n",
       " 'template',\n",
       " 'Autowired',\n",
       " 'React',\n",
       " 'Redis',\n",
       " '名称',\n",
       " 'data',\n",
       " 'type',\n",
       " '中心',\n",
       " 'handleStatusChange',\n",
       " 'app',\n",
       " '特性',\n",
       " 'mod',\n",
       " 'demo',\n",
       " 'context',\n",
       " 'callback',\n",
       " '案例',\n",
       " 'index',\n",
       " 'ChatAPI',\n",
       " '工具',\n",
       " 'preds',\n",
       " '规范',\n",
       " '事情',\n",
       " '工具类',\n",
       " 'andleStatusChange',\n",
       " '客户端开发',\n",
       " '__',\n",
       " 'idx',\n",
       " 'UIEvent',\n",
       " 'fun',\n",
       " 'viewplus',\n",
       " 'world',\n",
       " 'createBundleRender',\n",
       " 'ssr',\n",
       " 'Object',\n",
       " 'npm',\n",
       " '元素',\n",
       " 'componentDidMount',\n",
       " 'FriendStatusWithCounter',\n",
       " 'Thread1',\n",
       " 'err',\n",
       " 'bing',\n",
       " 'max',\n",
       " '类型',\n",
       " '利用',\n",
       " 'Runable',\n",
       " '时期',\n",
       " '功能',\n",
       " 'logger',\n",
       " '闭包',\n",
       " 'ViewPlus',\n",
       " '目录',\n",
       " 'error',\n",
       " 'decreaseCallMonitor',\n",
       " '原理',\n",
       " 'message',\n",
       " '单页',\n",
       " 'port',\n",
       " 'setIsOnline',\n",
       " 'div',\n",
       " 'group',\n",
       " 'host',\n",
       " '字符串',\n",
       " 'mWebView',\n",
       " 'curryN',\n",
       " 'pluck',\n",
       " 'extends',\n",
       " 'JedisCluster',\n",
       " 'entryclient',\n",
       " '队列',\n",
       " 'nextElement',\n",
       " '配置项',\n",
       " '作者',\n",
       " 'hset',\n",
       " 'not',\n",
       " 'runNative',\n",
       " 'jvm',\n",
       " 'ios',\n",
       " 'JedisClient',\n",
       " 'uiDialog',\n",
       " 'require',\n",
       " 'callMonitorInfo',\n",
       " 'hget',\n",
       " 'and',\n",
       " 'use',\n",
       " 'asMoreElements',\n",
       " 'JSONObject',\n",
       " 'google',\n",
       " 'github',\n",
       " '首屏',\n",
       " '速度',\n",
       " 'implements',\n",
       " 'componentWillUnmount',\n",
       " '版本号',\n",
       " 'org',\n",
       " 'AmqpConfig',\n",
       " '安卓',\n",
       " '基本',\n",
       " 'func',\n",
       " 'might',\n",
       " 'JedisTool',\n",
       " 'Exception',\n",
       " 'defa',\n",
       " 'effect',\n",
       " '核心',\n",
       " '概念',\n",
       " '前后端分离',\n",
       " '子节点',\n",
       " 'baidu',\n",
       " '用户',\n",
       " 'bridge',\n",
       " '静态',\n",
       " 'http',\n",
       " 'springboot',\n",
       " 'clean',\n",
       " 'are',\n",
       " 'TerminateDTO',\n",
       " 'thread',\n",
       " 'getName',\n",
       " 'WrappedComponent',\n",
       " '贡献',\n",
       " '远程',\n",
       " 'element',\n",
       " '交易',\n",
       " 'TERMINATE',\n",
       " 'len',\n",
       " 'Hybrid',\n",
       " 'hybrid',\n",
       " 'subscribeToFriendStatus',\n",
       " '入口',\n",
       " 'useCount',\n",
       " 'post',\n",
       " 'IVWEB',\n",
       " '工程',\n",
       " 'components',\n",
       " '样子',\n",
       " 'mount',\n",
       " 'text',\n",
       " 'code',\n",
       " '内容',\n",
       " 'utf',\n",
       " '分析器',\n",
       " 'global',\n",
       " 'myname',\n",
       " '评论',\n",
       " 'content',\n",
       " 'demoMixin',\n",
       " '运行环境',\n",
       " '类继承',\n",
       " 'sleep',\n",
       " 'Promise',\n",
       " 'dependency',\n",
       " '周刊',\n",
       " 'analysis',\n",
       " 'beans',\n",
       " '建议',\n",
       " '楼主',\n",
       " 'del',\n",
       " 'isN',\n",
       " 'cdn',\n",
       " 'Component',\n",
       " 'enable',\n",
       " 'componentDidCatch',\n",
       " 'babel',\n",
       " '副作用',\n",
       " 'cases',\n",
       " 'cpu',\n",
       " 'doSomething',\n",
       " 'yet',\n",
       " 'plugin',\n",
       " 'theId',\n",
       " '浏览器',\n",
       " 'JedisTest',\n",
       " 'order',\n",
       " 'home',\n",
       " '流量',\n",
       " 'box',\n",
       " '阈值',\n",
       " 'Value',\n",
       " '异步操作',\n",
       " '体积',\n",
       " 'rgs',\n",
       " '进程',\n",
       " 'Hook',\n",
       " 'artifactId',\n",
       " 'component',\n",
       " '标记',\n",
       " 'func1',\n",
       " 'sever',\n",
       " 'printStackTrace',\n",
       " '协议',\n",
       " '语言',\n",
       " '资源共享',\n",
       " 'elements',\n",
       " 'higher',\n",
       " 'componentDidUpdate',\n",
       " 'customerId',\n",
       " '#__',\n",
       " 'currentThread',\n",
       " '可重入',\n",
       " 'HANDLER',\n",
       " 'unsubscribe',\n",
       " '后者',\n",
       " '条件',\n",
       " '解决方案',\n",
       " 'HostAndPort',\n",
       " 'Key',\n",
       " 'koa',\n",
       " 'There',\n",
       " 'plain',\n",
       " 'subscribe',\n",
       " 'html',\n",
       " '关系',\n",
       " 'vplus',\n",
       " 'InterruptedException',\n",
       " 'isNumber',\n",
       " 'block',\n",
       " '函数声明',\n",
       " 'deep',\n",
       " '金融',\n",
       " '代理',\n",
       " 'add',\n",
       " 'doFireEvent',\n",
       " 'version',\n",
       " 'objectMapper',\n",
       " 'Synchronized',\n",
       " 'amp',\n",
       " 'super',\n",
       " 'statef',\n",
       " '古老',\n",
       " '容灾',\n",
       " 'else',\n",
       " '实际',\n",
       " 'Tobias',\n",
       " 'unsubscribeFromFriendStatus',\n",
       " 'unmount',\n",
       " 'springframework',\n",
       " 'Thread2',\n",
       " 'getSnapshotBeforeUpdate',\n",
       " 'evaluateJavascript',\n",
       " 'groupId',\n",
       " 'logic',\n",
       " '示例',\n",
       " '程序',\n",
       " '返回结果',\n",
       " '子类',\n",
       " 'nnotation',\n",
       " '小时',\n",
       " 'case',\n",
       " 'reduce',\n",
       " 'BINDING',\n",
       " 'json字符串',\n",
       " 'have',\n",
       " '客户端程序',\n",
       " 'thread1',\n",
       " 'factory',\n",
       " 'the',\n",
       " 'window',\n",
       " 'www',\n",
       " '节点',\n",
       " '系统',\n",
       " 'degrade',\n",
       " 'script',\n",
       " 'JSON',\n",
       " 'private',\n",
       " 'soon',\n",
       " '过程',\n",
       " 'dddyyy',\n",
       " 'escope',\n",
       " 'terminateDTO',\n",
       " '意思',\n",
       " 'then',\n",
       " '内置',\n",
       " '变形',\n",
       " '小伙伴',\n",
       " 'AST',\n",
       " '注意事项',\n",
       " '环境',\n",
       " '集群',\n",
       " 'cnblogs',\n",
       " 'https',\n",
       " 'length',\n",
       " 'stringify',\n",
       " '哔哩',\n",
       " 'PURE',\n",
       " '变量提升',\n",
       " '热加载',\n",
       " 'getJSONObject',\n",
       " '中文版',\n",
       " '符合规范',\n",
       " '全局变量',\n",
       " 'Runnable',\n",
       " 'ck2',\n",
       " '优质',\n",
       " 'Hoos',\n",
       " 'Google',\n",
       " 'getCode',\n",
       " 'bug',\n",
       " 'IOS',\n",
       " '原文',\n",
       " 'copy',\n",
       " 'DataProvider',\n",
       " '数量',\n",
       " 'nexElement',\n",
       " 'CALLMONITOR',\n",
       " 'still',\n",
       " 'messageHandlers',\n",
       " 'elimination',\n",
       " 'showCode',\n",
       " 'statevar',\n",
       " '整数',\n",
       " 'Our',\n",
       " 'FAQ',\n",
       " '局部',\n",
       " 'Scopeswitch',\n",
       " 'Cas2',\n",
       " 'methods',\n",
       " 'rse',\n",
       " 'toString',\n",
       " '等价',\n",
       " '大会',\n",
       " '磨平',\n",
       " '银行',\n",
       " 'CommonJS',\n",
       " 'Foo',\n",
       " 'degrage',\n",
       " '可扩展的',\n",
       " 'tml3',\n",
       " '样板',\n",
       " 'mark',\n",
       " '第三方库',\n",
       " '指向',\n",
       " '内核',\n",
       " 'customerBusinessInfoMapper',\n",
       " '标题',\n",
       " '公平锁',\n",
       " 'wrapper',\n",
       " 'JsBridgeContext',\n",
       " '小心',\n",
       " 'possible',\n",
       " 'width',\n",
       " 'only',\n",
       " '迭代器',\n",
       " 'ip地址',\n",
       " '应用开发',\n",
       " 'useStateuseState',\n",
       " 'them',\n",
       " '中断',\n",
       " '调试工具',\n",
       " '数据结构',\n",
       " 'vscode',\n",
       " 'right',\n",
       " 'third',\n",
       " '工厂模式',\n",
       " 'early',\n",
       " 'bind',\n",
       " 'Jiiiiiin',\n",
       " '载体',\n",
       " 'writeValueAsString',\n",
       " '数字',\n",
       " '夏令营',\n",
       " 'store',\n",
       " 'json对象',\n",
       " 'signSalespersonId',\n",
       " '公众号',\n",
       " 'getComponent',\n",
       " '东西',\n",
       " 'break',\n",
       " 'Android',\n",
       " 'nesting',\n",
       " 'split',\n",
       " '成本',\n",
       " '阶段',\n",
       " 'moment',\n",
       " '回源',\n",
       " '分隔符',\n",
       " 'slb',\n",
       " 'reqire',\n",
       " '大量',\n",
       " 'Node',\n",
       " '启动脚本',\n",
       " 'vuessr',\n",
       " '最佳实践',\n",
       " '线程安全',\n",
       " 'time',\n",
       " 'example',\n",
       " 'lifecycle',\n",
       " '源码',\n",
       " 'showLong',\n",
       " '计算机',\n",
       " 'Unmount',\n",
       " 'Components',\n",
       " 'Hookscustom',\n",
       " 'customerTerminate',\n",
       " '接口类型',\n",
       " '人员',\n",
       " '程序代码',\n",
       " 'useEffectuseEffect',\n",
       " '列表',\n",
       " '边际',\n",
       " '字符',\n",
       " '中国',\n",
       " 'RabbitListener',\n",
       " 'gap',\n",
       " 'rty',\n",
       " 'entryserver',\n",
       " 'compile',\n",
       " '层层',\n",
       " 'but',\n",
       " '构造方法',\n",
       " 'Level',\n",
       " '结论',\n",
       " 'Block',\n",
       " 'bottom',\n",
       " '生态',\n",
       " '模块安装',\n",
       " '健壮性',\n",
       " '开发者',\n",
       " 'CountStatus',\n",
       " 'signTime',\n",
       " '传统',\n",
       " '原作者',\n",
       " 'ecmascript',\n",
       " '树形图',\n",
       " 'vincentdchan',\n",
       " '自适应',\n",
       " 'simpler',\n",
       " 'htmlweb',\n",
       " 'interface',\n",
       " '程序运行',\n",
       " '上图',\n",
       " 'setConst',\n",
       " '可读性',\n",
       " '扫码',\n",
       " '全局对象',\n",
       " '前端应用',\n",
       " 'Enter',\n",
       " 'Medium',\n",
       " 'arguments',\n",
       " '谢谢',\n",
       " '懒加载',\n",
       " 'Forfor',\n",
       " 'dingyu',\n",
       " '学生',\n",
       " 'serve',\n",
       " '零配置',\n",
       " '身份认证',\n",
       " 'rabbitmq',\n",
       " 'protocol',\n",
       " 'also',\n",
       " '运行时',\n",
       " 'spring',\n",
       " '广州',\n",
       " 'jsimport',\n",
       " '返回值',\n",
       " 'seccuess',\n",
       " '阿莫',\n",
       " '导包',\n",
       " 'support',\n",
       " '顶层',\n",
       " '版本',\n",
       " 'queues',\n",
       " 'tible',\n",
       " '原因',\n",
       " '架构',\n",
       " '链子',\n",
       " '含义',\n",
       " '索性',\n",
       " 'Maven',\n",
       " '指南',\n",
       " '形状',\n",
       " 'Iterator',\n",
       " 'jar',\n",
       " '安利',\n",
       " 'oject',\n",
       " '高阶',\n",
       " 'debug',\n",
       " 'think',\n",
       " 'integrations',\n",
       " '重新运行',\n",
       " '一个对象',\n",
       " '用例',\n",
       " '函数调用',\n",
       " 'Demo',\n",
       " '命名',\n",
       " 'ToastUtils',\n",
       " 'word',\n",
       " 'clientMainfest',\n",
       " 'webkit',\n",
       " '中加',\n",
       " '环境变量',\n",
       " 'label',\n",
       " '企业级',\n",
       " '笔记',\n",
       " '安卓类',\n",
       " '云南',\n",
       " 'libraries',\n",
       " 'git仓库',\n",
       " '效率',\n",
       " 'DOM',\n",
       " '凡事',\n",
       " 'INITIAL',\n",
       " 'CallMonitorInfo',\n",
       " 'mixin',\n",
       " 'asyncData',\n",
       " '不太想',\n",
       " 'dist',\n",
       " 'scroller',\n",
       " 'createRenderer',\n",
       " '清理缓存',\n",
       " '前端架构',\n",
       " 'visual',\n",
       " 'Top',\n",
       " 'own',\n",
       " 'undefined',\n",
       " '开源项目',\n",
       " 'xxx',\n",
       " '上周末',\n",
       " 'koawe',\n",
       " 'COLLECTION',\n",
       " 'most',\n",
       " '甲方',\n",
       " 'Classclass',\n",
       " '技术',\n",
       " 'JedisClientCluster',\n",
       " '函数返回',\n",
       " '发消息',\n",
       " 'func2',\n",
       " '流程',\n",
       " '公平',\n",
       " 'Hello',\n",
       " 'Test1',\n",
       " 'v16',\n",
       " 'DECREASE',\n",
       " 'CPU',\n",
       " '树结构',\n",
       " '空格',\n",
       " '分段',\n",
       " '全部',\n",
       " '重入锁',\n",
       " 'some',\n",
       " '应用技术',\n",
       " '块级作用域',\n",
       " 'internal',\n",
       " '动机',\n",
       " 'css',\n",
       " 'structure',\n",
       " 'RabbitHandler',\n",
       " '页面开发',\n",
       " '原生',\n",
       " 'JavascriptInterface',\n",
       " '干嘛',\n",
       " 'HooksHooks',\n",
       " 'uncommon',\n",
       " 'onClick',\n",
       " '使用率',\n",
       " 'ddJavascriptInterface',\n",
       " '占位符',\n",
       " 'renderItem',\n",
       " '思维',\n",
       " 'its',\n",
       " 'mixins',\n",
       " 'mini',\n",
       " '用途',\n",
       " '所需',\n",
       " '远远不够',\n",
       " 'ECMAScript',\n",
       " '次数',\n",
       " '规则',\n",
       " 'EXCHANGE',\n",
       " 'rollup',\n",
       " 'let',\n",
       " '经历',\n",
       " 'sufficient',\n",
       " '损失',\n",
       " 'VueSSR',\n",
       " '干货',\n",
       " 'main方法',\n",
       " 'Reentrantlock',\n",
       " 'JedisClientPool',\n",
       " '总结',\n",
       " 'resp',\n",
       " 'convertAndSend',\n",
       " 'Feflow',\n",
       " 'TypeScript',\n",
       " 'temlate',\n",
       " 'Often',\n",
       " '上线',\n",
       " 'DevTools',\n",
       " 'EnumCustomerStatus',\n",
       " 'typings',\n",
       " 'sideEffect',\n",
       " 'encoding',\n",
       " '播放页',\n",
       " '选项',\n",
       " 'hasMoreElements',\n",
       " '优势',\n",
       " 'signSalesperson',\n",
       " '手机',\n",
       " '钩子',\n",
       " 'deepEqual',\n",
       " 'container',\n",
       " '中间件',\n",
       " 'ready',\n",
       " '同学会',\n",
       " '方面',\n",
       " 'ImmutableMap',\n",
       " 'liTags',\n",
       " 'pply',\n",
       " '思路',\n",
       " 'ckplugin',\n",
       " '节奏',\n",
       " 'weekly',\n",
       " 'final',\n",
       " '前端js',\n",
       " '术语',\n",
       " '普通',\n",
       " '测试类',\n",
       " '回车换行',\n",
       " '机制',\n",
       " '分割字符串',\n",
       " 'properties',\n",
       " '废话',\n",
       " 'single',\n",
       " '同步请求',\n",
       " 'prop',\n",
       " 'cover',\n",
       " '性能',\n",
       " '有点',\n",
       " 'ram',\n",
       " '经验',\n",
       " '容器',\n",
       " 'vincentdcha',\n",
       " 'func5',\n",
       " '记录',\n",
       " 'Order',\n",
       " 'help',\n",
       " '要将',\n",
       " 'Click',\n",
       " 'will',\n",
       " '权限控制',\n",
       " '偏向',\n",
       " '命令',\n",
       " '区分',\n",
       " 'child',\n",
       " '父节点',\n",
       " 'equivalents',\n",
       " '生命周期',\n",
       " 'CUSTOMER',\n",
       " '效果',\n",
       " '关键',\n",
       " '非阻塞',\n",
       " '5e',\n",
       " 'Runnable接口',\n",
       " '会灰',\n",
       " 'Reference',\n",
       " 'elseif',\n",
       " '大大降低',\n",
       " '中都',\n",
       " '前人',\n",
       " '机会',\n",
       " '原本',\n",
       " '项目打包',\n",
       " 'config',\n",
       " 'video',\n",
       " '调度',\n",
       " '基础',\n",
       " 'getCustomerId',\n",
       " 'info',\n",
       " 'tterns',\n",
       " '缓存机制',\n",
       " '错误',\n",
       " '目的',\n",
       " 'nodes',\n",
       " 'UI15672',\n",
       " 'like',\n",
       " '异步通知',\n",
       " 'chunks',\n",
       " 'with',\n",
       " 'hell',\n",
       " '_&',\n",
       " 'switch',\n",
       " '道理',\n",
       " 'updateCustomer',\n",
       " 'place',\n",
       " 'setState',\n",
       " 'Example',\n",
       " '项目一',\n",
       " 'throws',\n",
       " 'jdk1',\n",
       " 'Functionfunction',\n",
       " '地狱',\n",
       " 'readValue',\n",
       " '用法',\n",
       " 'createRender',\n",
       " 'Wikipedia',\n",
       " 'dead',\n",
       " 'ide',\n",
       " 'postMessage',\n",
       " 'outlet',\n",
       " 'returns',\n",
       " 'But',\n",
       " 'indexOf',\n",
       " 'junit',\n",
       " 'fun4',\n",
       " '索引',\n",
       " 'click',\n",
       " '文本',\n",
       " '无法',\n",
       " 'Higher',\n",
       " 'lifecycles',\n",
       " 'virtual',\n",
       " 'classes',\n",
       " 'State',\n",
       " '格式',\n",
       " 'business',\n",
       " '潜力',\n",
       " '干杯',\n",
       " '整体',\n",
       " 'target',\n",
       " 'all',\n",
       " '同步方法',\n",
       " '区别',\n",
       " '手脚',\n",
       " '代表',\n",
       " '基本操作',\n",
       " 'Some',\n",
       " '想象力',\n",
       " 'fun3',\n",
       " '垃圾收集',\n",
       " 'goal',\n",
       " 'plan',\n",
       " 'emitErr',\n",
       " '原则',\n",
       " 'can',\n",
       " 'both',\n",
       " '指令',\n",
       " '办法',\n",
       " 'nodessr',\n",
       " '趋势',\n",
       " '地址',\n",
       " '搜索引擎',\n",
       " '开发效率',\n",
       " '本地存储',\n",
       " '调用顺序',\n",
       " 'Render',\n",
       " 'rambda',\n",
       " 'rseObject',\n",
       " '农信',\n",
       " 'isFunction',\n",
       " 'may',\n",
       " '端口',\n",
       " '范围',\n",
       " 'native',\n",
       " '文件路径',\n",
       " '语句',\n",
       " 'Flow',\n",
       " 'STATE',\n",
       " 'fun2',\n",
       " 'hkey',\n",
       " 'clientmanifest',\n",
       " '库中',\n",
       " 'ck4',\n",
       " '导师',\n",
       " 'very',\n",
       " 'Catchtry',\n",
       " '成员',\n",
       " '顺序',\n",
       " '目标',\n",
       " '自旋锁',\n",
       " '写文章',\n",
       " '压力',\n",
       " 'sevrer',\n",
       " '分支',\n",
       " 'DATA',\n",
       " 'ajax',\n",
       " '画出',\n",
       " 'rabbitTemplate',\n",
       " 'your',\n",
       " 'ReactConf',\n",
       " 'Props',\n",
       " '题外话',\n",
       " 'bet',\n",
       " '典型',\n",
       " 'Sean',\n",
       " '单继承',\n",
       " '访问量',\n",
       " 'es6',\n",
       " 'way',\n",
       " '黑科技',\n",
       " '跨域问题',\n",
       " 'nginx',\n",
       " 'feday',\n",
       " 'ConcurrentHashMap',\n",
       " 'Cas',\n",
       " '专门',\n",
       " '动态',\n",
       " 'fun1',\n",
       " 'alpha',\n",
       " 'Error',\n",
       " '极端']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29928298, 1.70474809, 0.31845373, 1.70474809, 0.        ,\n",
       "       0.78845736, 1.29928298, 2.39789527, 1.70474809, 2.39789527,\n",
       "       0.6061358 , 0.2006707 , 1.01160091, 1.70474809, 0.45198512,\n",
       "       1.70474809, 0.45198512, 2.39789527, 0.45198512, 2.39789527])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfModel.idf.toArray()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV值与IDF的值结果， TFIDF的结果\n",
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "cv_model = CountVectorizerModel.load(\"hdfs://hadoop-master:9000/headlines/models/CV.model\")\n",
    "\n",
    "from pyspark.ml.feature import IDFModel\n",
    "idf_model = IDFModel.load(\"hdfs://hadoop-master:9000/headlines/models/IDF.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [('代码', 1.29928298), (), ()]\n",
    "\n",
    "# [['代码', 1.29928298, 0], ['', , ]]\n",
    "\n",
    "# 必须保存词和索引的中间结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cv_model.transform(words_df)\n",
    "tfidf_res = idf_model.transform(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "|article_id|channel_id|               words|       countFeatures|         idfFeatures|\n",
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "|     14396|        18|[python, 项目, 平台, ...|(1837,[1,2,3,9,12...|(1837,[1,2,3,9,12...|\n",
      "|     14400|        18|[python, PySide2,...|(1837,[1,3,13,15,...|(1837,[1,3,13,15,...|\n",
      "|     14401|        18|[python, Python, ...|(1837,[2,3,7,9,13...|(1837,[2,3,7,9,13...|\n",
      "|     14402|        18|[python, PySide2,...|(1837,[1,2,3,6,9,...|(1837,[1,2,3,6,9,...|\n",
      "|     14405|        18|[python, Python3,...|(1837,[7,44,69,80...|(1837,[7,44,69,80...|\n",
      "|     14406|        18|[python, Python, ...|(1837,[7,33,80,13...|(1837,[7,33,80,13...|\n",
      "|     14407|        18|[python, python, ...|(1837,[2,6,7,11,1...|(1837,[2,6,7,11,1...|\n",
      "|     14410|        18|[python, time, 模块...|(1837,[13,16,23,2...|(1837,[13,16,23,2...|\n",
      "|     14411|        18|[python, random, ...|(1837,[13,16,50,8...|(1837,[13,16,50,8...|\n",
      "|     14413|        18|[python, Python, ...|(1837,[2,3,4,6,7,...|(1837,[2,3,4,6,7,...|\n",
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取出文章的TFIDF的值，输出[\"article_id\", \"channel_id\", \"index\", \"tfidf\"]\n",
    "def _func(partitions):\n",
    "    TOPK=20\n",
    "    for row in partitions:\n",
    "        _ = list(zip(row.idfFeatures.indices, row.idfFeatures.values))\n",
    "        _ = sorted(_, key=lambda x: x[1], reverse=True)\n",
    "        # 对结果取出TOPK\n",
    "        result = _[:TOPK]\n",
    "        for word_index, tfidf in result:\n",
    "            yield row.article_id, row.channel_id, int(word_index), round(float(tfidf), 4)\n",
    "\n",
    "_keywordsIndexOfTFIDF = tfidf_res.rdd.mapPartitions(_func).toDF(['article_id', 'channel_id', 'index', 'tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+---------+\n",
      "|article_id|channel_id|index|    tfidf|\n",
      "+----------+----------+-----+---------+\n",
      "|     12237|        18|    0|1700.1077|\n",
      "|     12237|        18|    8| 220.6064|\n",
      "|     12237|        18|   10| 211.0148|\n",
      "|     12237|        18|   12| 134.6751|\n",
      "|     12237|        18|    4| 132.9704|\n",
      "|     12237|        18|   11| 121.0371|\n",
      "|     12237|        18|   20|  115.099|\n",
      "|     12237|        18|   39|  93.5179|\n",
      "|     12237|        18|   43|  88.7221|\n",
      "|     12237|        18|   48|  83.9263|\n",
      "|     12237|        18|   49|  81.5284|\n",
      "|     12237|        18|   52|  81.5284|\n",
      "|     12237|        18|   55|  81.5284|\n",
      "|     12237|        18|    1|  78.9049|\n",
      "|     12237|        18|   28|  78.4184|\n",
      "|     12237|        18|   59|  76.7326|\n",
      "|     12237|        18|   60|  76.7326|\n",
      "|     12237|        18|   61|  76.7326|\n",
      "|     12237|        18|   62|  76.7326|\n",
      "|     12237|        18|   68|  71.9369|\n",
      "+----------+----------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_keywordsIndexOfTFIDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出索引对应的词然后保存\n",
    "idf_keywords_values = oa.spark.sql(\"select keyword, index idx from idf_keywords_values\")\n",
    "\n",
    "tfidf_keyword_values = _keywordsIndexOfTFIDF.join(idf_keywords_values, idf_keywords_values.idx==_keywordsIndexOfTFIDF.index).select([\"article_id\", \"channel_id\", \"keyword\", \"tfidf\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+---------+\n",
      "|article_id|channel_id| keyword|    tfidf|\n",
      "+----------+----------+--------+---------+\n",
      "|     12238|        18|     var|    18.19|\n",
      "|     12251|        18|      属性|  18.2088|\n",
      "|     12253|        18|   https|  71.9369|\n",
      "|     12238|        18|      脚本|  19.1832|\n",
      "|     12245|        18|document|   23.979|\n",
      "|     12247|        18|     com| 131.8842|\n",
      "|     12249|        18|      功能|  79.1305|\n",
      "|     12237|        18|      &#|1700.1077|\n",
      "|     12238|        18|      &#|1357.2087|\n",
      "|     12243|        18|      &#|  527.537|\n",
      "|     12245|        18|      &#| 335.7053|\n",
      "|     12247|        18|      &#|2074.1794|\n",
      "|     12249|        18|      &#|  19.1832|\n",
      "|     12251|        18|      &#| 179.8421|\n",
      "|     12252|        18|      &#| 134.2821|\n",
      "|     12253|        18|      &#| 563.5054|\n",
      "|     12254|        18|      &#| 505.9559|\n",
      "|     12251|        18|      阶段|  19.1832|\n",
      "|     12247|        18|      列表|  47.9579|\n",
      "|     12238|        18|      图片|  16.1856|\n",
      "+----------+----------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_keyword_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对原始数据进行Texrank的计算\n",
    "# 分词\n",
    "def textrank(partition):\n",
    "    import os\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/root/words\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path).readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    class TextRank(jieba.analyse.TextRank):\n",
    "        def __init__(self, window=20, word_min_len=2):\n",
    "            super(TextRank, self).__init__()\n",
    "            self.span = window  # 窗口大小\n",
    "            self.word_min_len = word_min_len  # 单词的最小长度\n",
    "            # 要保留的词性，根据jieba github ，具体参见https://github.com/baidu/lac\n",
    "            self.pos_filt = frozenset(\n",
    "                ('n', 'x', 'eng', 'f', 's', 't', 'nr', 'ns', 'nt', \"nw\", \"nz\", \"PER\", \"LOC\", \"ORG\"))\n",
    "\n",
    "        def pairfilter(self, wp):\n",
    "            \"\"\"过滤条件，返回True或者False\"\"\"\n",
    "\n",
    "            if wp.flag == \"eng\":\n",
    "                if len(wp.word) <= 2:\n",
    "                    return False\n",
    "\n",
    "            if wp.flag in self.pos_filt and len(wp.word.strip()) >= self.word_min_len \\\n",
    "                    and wp.word.lower() not in stopwords_list:\n",
    "                return True\n",
    "    # TextRank过滤窗口大小为5，单词最小为2\n",
    "    textrank_model = TextRank(window=5, word_min_len=2)\n",
    "    allowPOS = ('n', \"x\", 'eng', 'nr', 'ns', 'nt', \"nw\", \"nz\", \"c\")\n",
    "\n",
    "    for row in partition:\n",
    "        tags = textrank_model.textrank(row.sentence, topK=20, withWeight=True, allowPOS=allowPOS, withFlag=False)\n",
    "        for tag in tags:\n",
    "            yield row.article_id, row.channel_id, tag[0], tag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_values = article_data.rdd.mapPartitions(textrank).toDF([\"article_id\", \"channel_id\", \"keyword\", \"textrank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------------------+\n",
      "|article_id|channel_id|keyword|           textrank|\n",
      "+----------+----------+-------+-------------------+\n",
      "|     14396|        18|  style|                1.0|\n",
      "|     14396|        18|     pa| 0.9849467862313341|\n",
      "|     14396|        18|  color|0.41896834977762765|\n",
      "|     14396|        18|    org|0.24315619609735817|\n",
      "|     14396|        18|     机构|0.23620100962683405|\n",
      "|     14396|        18| models|0.21318650119167998|\n",
      "|     14396|        18|    tml|0.15742118310210823|\n",
      "|     14396|        18|     页面|0.14816744056498826|\n",
      "|     14396|        18|     .h|0.13636906517549746|\n",
      "|     14396|        18|cnblogs|0.13517472127989524|\n",
      "|     14396|        18|   user|0.10779275550595868|\n",
      "|     14396|        18|     课程|0.09872653607691473|\n",
      "|     14396|        18|   code|0.08164071422330386|\n",
      "|     14396|        18|    fav|0.08113864613085245|\n",
      "|     14396|        18| detail|0.08087848891203411|\n",
      "|     14396|        18|request|0.07755996658963021|\n",
      "|     14396|        18|    src|0.07294470434964236|\n",
      "|     14396|        18|   base|0.07256248963925095|\n",
      "|     14396|        18|     项目|0.07176049022134386|\n",
      "|     14396|        18|  https|0.07082609124097904|\n",
      "+----------+----------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textrank_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算关键词最后的权重，Textank  * IDF\n",
    "\n",
    "\n",
    "idf = oa.spark.sql(\"select * from idf_keywords_values\")\n",
    "idf = idf.withColumnRenamed(\"keyword\", \"keyword1\")\n",
    "result = textrank_values.join(idf,textrank_values.keyword==idf.keyword1)\n",
    "keywords_res = result.withColumn(\"weights\", result.textrank * result.idf).select([\"article_id\", \"channel_id\", \"keyword\", \"weights\"])\n",
    "\n",
    "\n",
    "\n",
    "# 20个Keyword，对应的权重，文章ID，channel_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-------------------+\n",
      "|article_id|channel_id|   keyword|            weights|\n",
      "+----------+----------+----------+-------------------+\n",
      "|     12237|        18|    import| 0.1252362492618782|\n",
      "|     12251|        18|       amp| 0.3576306801736144|\n",
      "|     12245|        18|       jpg| 0.6006144883033138|\n",
      "|     12249|        18|       jpg| 0.6446667069452843|\n",
      "|     12251|        18|       jpg| 0.5850464157387808|\n",
      "|     12252|        18|       jpg| 0.8118225634390153|\n",
      "|     12243|        18|        老张| 0.8903452854624969|\n",
      "|     12243|        18|    Engine| 0.4449572692443991|\n",
      "|     12243|        18|    Spider| 0.9320063800229654|\n",
      "|     12247|        18|      应用程序|0.18128233155574108|\n",
      "|     12253|        18|        3d| 0.2774573382517545|\n",
      "|     12254|        18|        信息| 0.1444381388490212|\n",
      "|     12237|        18|      code|0.28890263752763984|\n",
      "|     12247|        18|      code| 1.2320096014955921|\n",
      "|     12238|        18|  settings|0.25486933323286315|\n",
      "|     12252|        18|       UTF| 0.7278570677291955|\n",
      "|     12243|        18|Downloader| 0.6939226326693103|\n",
      "|     12249|        18|      core| 0.6802420388128592|\n",
      "|     12237|        18|       区块链|0.31787589084791096|\n",
      "|     12238|        18|      href|  0.263578140172942|\n",
      "+----------+----------+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_res.registerTempTable(\"temptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_weights_list = oa.spark.sql(\"select article_id, min(channel_id) channel_id, collect_list(keyword) keywords, collect_list(weights) weights from temptable group by article_id\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|             weights|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     14402|        18|[internationaliza...|[1.48381515956148...|\n",
      "|     14413|        18|[文件, code, silver...|[0.07438046215156...|\n",
      "|     14405|        18|[whl, img2018, al...|[3.05649292647403...|\n",
      "|     14410|        18|[struct, h2, 格式化时...|[1.24688935273482...|\n",
      "|     14400|        18|[国际化, code, uic, ...|[0.84764461910118...|\n",
      "|     14411|        18|[形式, code, choice...|[0.48927309340723...|\n",
      "|     14406|        18|[uri, href, douba...|[1.66602345862538...|\n",
      "|     14401|        18|[文件, code, yjk137...|[0.19999460241549...|\n",
      "|     14407|        18|[文件, code, 程序, h2...|[0.19371582994861...|\n",
      "|     14396|        18|[.h, code, detail...|[0.19628123037228...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_weights_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_weights_to_dict(row):\n",
    "    return row.article_id, row.channel_id, dict(zip(row.keywords, row.weights))\n",
    "    \n",
    "keywords = keyword_weights_list.rdd.map(keyword_weights_to_dict).toDF(['article_id', 'channel_id', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|            keywords|\n",
      "+----------+----------+--------------------+\n",
      "|     14402|        18|Map(TRANSLATOR ->...|\n",
      "|     14413|        18|Map(pre -> 0.4482...|\n",
      "|     14405|        18|Map(pre -> 3.3062...|\n",
      "|     14410|        18|Map(pre -> 0.7255...|\n",
      "|     14400|        18|Map(style -> 2.68...|\n",
      "|     14411|        18|Map(pre -> 1.1641...|\n",
      "|     14406|        18|Map(豆瓣 -> 2.69946...|\n",
      "|     14401|        18|Map(__ -> 1.24893...|\n",
      "|     14407|        18|Map(pre -> 0.4141...|\n",
      "|     14396|        18|Map(fav -> 0.6634...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sql = \"\"\"\n",
    "                select t.article_id article_id2, collect_set(t.keyword) topics from tfidf_keywords_values t\n",
    "                inner join \n",
    "                textrank_keywords_values r\n",
    "                where t.keyword=r.keyword\n",
    "                group by article_id2\n",
    "                \"\"\"\n",
    "\n",
    "article_topics = oa.spark.sql(topic_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_profile = keywords.join(article_topics, keywords.article_id==article_topics.article_id2).select([\"article_id\", \"channel_id\", \"keywords\", \"topics\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|              topics|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     14402|        18|Map(TRANSLATOR ->...|[__, ctionChinese...|\n",
      "|     14405|        18|Map(pre -> 3.3062...|[Twisted, lfd, 32...|\n",
      "|     14413|        18|Map(pre -> 0.4482...|[字符串, dic2, dic, ...|\n",
      "|     14410|        18|Map(pre -> 0.7255...|[mktime, 时间差, beg...|\n",
      "|     14400|        18|Map(style -> 2.68...|[uic, designer, s...|\n",
      "|     14411|        18|Map(pre -> 1.1641...|[randomprint, lis...|\n",
      "|     14406|        18|Map(豆瓣 -> 2.69946...|[com, trusted, xx...|\n",
      "|     14401|        18|Map(__ -> 1.24893...|[__, run, area, m...|\n",
      "|     14396|        18|Map(fav -> 0.6634...|[课程, courses, fav...|\n",
      "|     14407|        18|Map(pre -> 0.4141...|[QiaoBa, copy, st...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_profile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做词向量模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过少量数据来演示训练\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "\n",
    "w2v = Word2Vec(vectorSize=100, inputCol='words', outputCol='model', minCount=3)\n",
    "w2v_model = w2v.fit(words_df)\n",
    "w2v_model.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/test.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求出增量文章的词向量，增量文章 一共10篇文章\n",
    "# 1、加载某个频道模型，得到每个词的向量\n",
    "from pyspark.ml.feature import Word2VecModel\n",
    "\n",
    "word_vec = Word2VecModel.load(\"hdfs://hadoop-master:9000/headlines/models/test.word2vec\")\n",
    "vectors = word_vec.getVectors()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|       word|              vector|\n",
      "+-----------+--------------------+\n",
      "|         合法|[-0.0025246678851...|\n",
      "|         字母|[-0.0040163993835...|\n",
      "|         范围|[-0.0020277597941...|\n",
      "|         海东|[5.36677252966910...|\n",
      "|        del|[-0.0019045806257...|\n",
      "|        标准库|[0.00404426921159...|\n",
      "|       反序列化|[1.56049733050167...|\n",
      "|application|[-0.0236849114298...|\n",
      "|     please|[0.00192741991486...|\n",
      "|         函数|[-0.0512114949524...|\n",
      "|       sha1|[0.00283131306059...|\n",
      "|       read|[-0.0286798775196...|\n",
      "|     number|[-0.0199127420783...|\n",
      "|  Formatter|[0.00314382021315...|\n",
      "|         小数|[8.44318245071917...|\n",
      "|     format|[-0.0776508525013...|\n",
      "|        for|[-0.0517615564167...|\n",
      "|         对象|[-0.0239426605403...|\n",
      "|     encode|[-0.0161938350647...|\n",
      "|    Chinese|[-0.0029618265107...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取频道的文章画像，得到文章画像的关键词，找到这些文章关键词对应词向量\n",
    "python_article_profile = article_profile.filter('channel_id=18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python_article_profile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+-------------------+\n",
      "|article_id|channel_id|             keyword|             weight|\n",
      "+----------+----------+--------------------+-------------------+\n",
      "|     14402|        18|                 app|  0.208940517619879|\n",
      "|     14402|        18|                  __|0.25509978230906344|\n",
      "|     14402|        18|                  语言|0.33137882507083766|\n",
      "|     14402|        18|               color| 1.2313221791323552|\n",
      "|     14402|        18|                 src|0.20449518445715634|\n",
      "|     14402|        18|           QtWidgets| 0.5726361541048846|\n",
      "|     14402|        18|                maya| 0.7393521059248234|\n",
      "|     14402|        18|internationalizat...| 1.4838151595614864|\n",
      "|     14402|        18|                  pa| 0.6228657329981744|\n",
      "|     14402|        18|               QtGui| 1.3120233092718885|\n",
      "|     14402|        18|                  .a| 0.1762622725949752|\n",
      "|     14402|        18|             cnblogs| 0.4812975085295756|\n",
      "|     14402|        18|          MainWindow| 1.0538394329209233|\n",
      "|     14402|        18|                Maya| 0.6631281574610763|\n",
      "|     14402|        18|             img2018| 0.6829967688738555|\n",
      "|     14402|        18|               style| 2.6818307378755373|\n",
      "|     14402|        18|               https| 0.1326924669954786|\n",
      "|     14402|        18|        QApplication| 0.8543516574642587|\n",
      "|     14402|        18|              pyside|  1.320878581646563|\n",
      "|     14402|        18|          TRANSLATOR| 0.7020457309085865|\n",
      "+----------+----------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将文章画像的字典， 词语与权重 进行展开\n",
    "python_article_profile.registerTempTable('profile')\n",
    "\n",
    "_articlekeywordsweight = oa.spark.sql(\"select article_id,  channel_id, keyword, weight from profile LATERAL VIEW explode(keywords) AS keyword, weight\")\n",
    "\n",
    "\n",
    "_articlekeywordsweight.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+-------------------+--------------------+--------------------+\n",
      "|article_id|channel_id|             keyword|             weight|                word|              vector|\n",
      "+----------+----------+--------------------+-------------------+--------------------+--------------------+\n",
      "|     14402|        18|                 app|  0.208940517619879|                 app|[-0.0554441921412...|\n",
      "|     14402|        18|                  __|0.25509978230906344|                  __|[-0.0427282340824...|\n",
      "|     14402|        18|                  语言|0.33137882507083766|                  语言|[-0.0039124097675...|\n",
      "|     14402|        18|                 src|0.20449518445715634|                 src|[-0.0818416625261...|\n",
      "|     14402|        18|           QtWidgets| 0.5726361541048846|           QtWidgets|[-0.0041199713014...|\n",
      "|     14402|        18|                maya| 0.7393521059248234|                maya|[-0.0028708176687...|\n",
      "|     14402|        18|internationalizat...| 1.4838151595614864|internationalizat...|[-0.0030698371119...|\n",
      "|     14402|        18|                  pa| 0.6228657329981744|                  pa|[-0.0654442608356...|\n",
      "|     14402|        18|               QtGui| 1.3120233092718885|               QtGui|[0.00218071579001...|\n",
      "|     14402|        18|                  .a| 0.1762622725949752|                  .a|[-0.0478109084069...|\n",
      "|     14402|        18|          MainWindow| 1.0538394329209233|          MainWindow|[0.00359705276787...|\n",
      "|     14402|        18|                Maya| 0.6631281574610763|                Maya|[0.00392441870644...|\n",
      "|     14402|        18|               https| 0.1326924669954786|               https|[-0.0522091984748...|\n",
      "|     14402|        18|        QApplication| 0.8543516574642587|        QApplication|[-0.0044388873502...|\n",
      "|     14402|        18|              pyside|  1.320878581646563|              pyside|[5.63721638172864...|\n",
      "|     14402|        18|          TRANSLATOR| 0.7020457309085865|          TRANSLATOR|[-0.0035150479525...|\n",
      "|     14405|        18|                 src| 1.2874095786561537|                 src|[-0.0818416625261...|\n",
      "|     14405|        18|                  pa|0.49939227855768215|                  pa|[-0.0654442608356...|\n",
      "|     14405|        18|             install| 1.4300466147090243|             install|[-0.0122618144378...|\n",
      "|     14405|        18|                 pip| 2.7436138673186976|                 pip|[-0.0050221672281...|\n",
      "+----------+----------+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_keyword_vec_weights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_keyword_vec_weights.registerTempTable(\"temptable\")\n",
    "\n",
    "def func(row):\n",
    "    x = 0\n",
    "    for v in row.vectors:\n",
    "        x += v\n",
    "        \n",
    "    return row.article_id, row.channel_id, x / len(row.vectors)\n",
    "\n",
    "article_vector = oa.spark.sql(\"select article_id, min(channel_id) channel_id, collect_set(vector) vectors from temptable group by article_id\").rdd.map(func).toDF(['article_id', 'channel_id', 'articlevector'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|       articlevector|\n",
      "+----------+----------+--------------------+\n",
      "|     14402|        18|[-0.0223212199198...|\n",
      "|     14405|        18|[-0.0333953801808...|\n",
      "|     14413|        18|[-0.0455277313478...|\n",
      "|     14410|        18|[-0.0175953126997...|\n",
      "|     14400|        18|[-0.0198630368769...|\n",
      "|     14411|        18|[-0.0407281115185...|\n",
      "|     14406|        18|[-0.0398771598314...|\n",
      "|     14401|        18|[-0.0343965302678...|\n",
      "|     14396|        18|[-0.0302773189032...|\n",
      "|     14407|        18|[-0.0404947499143...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、读取数据（保存到表当中向量），进行类型处理(数组到Vector)\n",
    "article_vector = oa.spark.sql(\"select article_id, articlevector from article_vector where channel_id=18 limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[article_id: int, articlevector: array<double>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "def _array_to_vector(row):\n",
    "    return row.article_id, Vectors.dense(row.articlevector)\n",
    "\n",
    "train = article_vector.rdd.map(_array_to_vector).toDF(['article_id', 'article_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[article_id: bigint, article_vector: vector]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRP进行fit\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "BRP = BucketedRandomProjectionLSH(inputCol='article_vector', outputCol='hashes', numHashTables=4.0, bucketLength=10.0)\n",
    "model = BRP.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = model.approxSimilarityJoin(train, train, 2.0, distCol='EuclideanDistance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[datasetA: struct<article_id:bigint,article_vector:vector,hashes:array<vector>>, datasetB: struct<article_id:bigint,article_vector:vector,hashes:array<vector>>, EuclideanDistance: double]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasetA:第一个train\n",
    "# datasetB:第二个train\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            datasetA|            datasetB| EuclideanDistance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|[13401,[0.0615712...|[14805,[0.1102852...|   0.4593524843945|\n",
      "|[13401,[0.0615712...|[17370,[0.0887140...|0.5058230219573121|\n",
      "|[15194,[0.0860524...|[14805,[0.1102852...|0.5690720608173139|\n",
      "|[14846,[0.1794535...|[14805,[0.1102852...| 0.596659479571255|\n",
      "|[15237,[0.0201966...|[14805,[0.1102852...|0.6234351626148141|\n",
      "|[13723,[0.2070807...|[14805,[0.1102852...|0.6299626564819212|\n",
      "|[13098,[0.1033995...|[14805,[0.1102852...|0.6400357825139292|\n",
      "|[14846,[0.1794535...|[17370,[0.0887140...|0.6486569730194188|\n",
      "|[15237,[0.0201966...|[17370,[0.0887140...|0.6741832657291263|\n",
      "|[15194,[0.0860524...|[17370,[0.0887140...| 0.682628319443476|\n",
      "|[13098,[0.1033995...|[17370,[0.0887140...|0.6965130281511644|\n",
      "|[13723,[0.2070807...|[17370,[0.0887140...|0.7355710550707689|\n",
      "|[13401,[0.0615712...|[15921,[0.1067969...|0.8067496608346719|\n",
      "|[15237,[0.0201966...|[15921,[0.1067969...|0.8326035956658631|\n",
      "|[14846,[0.1794535...|[15921,[0.1067969...|0.8761506466918182|\n",
      "|[14719,[-0.040560...|[14259,[-0.151868...|0.9272693614706403|\n",
      "|[15322,[0.1198567...|[14805,[0.1102852...|0.9983391099980293|\n",
      "|[13098,[0.1033995...|[15921,[0.1067969...|1.0100812751482826|\n",
      "|[15322,[0.1198567...|[17370,[0.0887140...|1.0268350234903272|\n",
      "|[15194,[0.0860524...|[15921,[0.1067969...|1.0454052151738307|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similar.sort(['EuclideanDistance']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hbase(partition):\n",
    "    import happybase\n",
    "    pool = happybase.ConnectionPool(size=3, host='hadoop-master')\n",
    "    \n",
    "    with pool.connection() as conn:\n",
    "        # 建议表的连接\n",
    "        table = conn.table('article_similar')\n",
    "        for row in partition:\n",
    "            if row.datasetA.article_id == row.datasetB.article_id:\n",
    "                pass\n",
    "            else:\n",
    "                table.put(str(row.datasetA.article_id).encode(),\n",
    "                         {\"similar:{}\".format(row.datasetB.article_id).encode(): b'%0.4f' % (row.EuclideanDistance)})\n",
    "        # 手动关闭所有的连接\n",
    "        conn.close()\n",
    "\n",
    "similar.foreachPartition(save_hbase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
